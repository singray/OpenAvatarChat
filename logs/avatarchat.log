Downloading hf-xet (3.0MiB)
Downloading ruff (11.1MiB)
Downloading modelscope (5.6MiB)
Downloading pygments (1.2MiB)
 Downloading pygments
 Downloading hf-xet
 Downloading modelscope
 Downloading ruff
Uninstalled 13 packages in 196ms
warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.
         If the cache and target directories are on different filesystems, hardlinking may not be supported.
         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.
Installed 13 packages in 202ms
2025-06-28 09:51:19.041 | INFO     | service.service_utils.service_config_loader:load_configs:23 - Load config with env default from /mnt/data/open-avatar-chat/opt/OpenAvatarChat/config/glut_tts_llm.yaml
2025-06-28 09:51:19.152 | INFO     | __main__:main:78 - service_config: host='0.0.0.0' port=8283 cert_file='ssl_certs/localhost.crt' cert_key='ssl_certs/localhost.key' rtc_config={'urls': <BoxList: ['turn:turn.120-224-27-114.turnserver:3478', 'turns:turn.120-224-27-114.turnserver:5349']>, 'username': 'admin', 'credential': 'admin@123~'}
2025-06-28 09:51:19.152 | INFO     | __main__:main:79 - engine_config: model_root='models' handler_search_path=['src/handlers'] handler_configs={'LamClient': {'module': 'client/h5_rendering_client/client_handler_lam', 'asset_path': 'lam_samples/060201.zip', 'concurrent_limit': 5}, 'SileroVad': {'module': 'vad/silerovad/vad_handler_silero', 'speaking_threshold': 0.5, 'start_delay': 2048, 'end_delay': 5000, 'buffer_look_back': 5000, 'speech_padding': 512}, 'SenseVoice': {'enabled': True, 'module': 'asr/sensevoice/asr_handler_sensevoice', 'model_name': 'iic/SenseVoiceSmall'}, 'CosyVoice': {'enabled': True, 'module': 'tts/cosyvoice/tts_handler_cosyvoice', 'api_url': 'http://127.0.0.1:40000/inference_zero_shot', 'model_name': 'iic/CosyVoice2-0.5B', 'ref_audio_path': '/mnt/data/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/asset/my_voice_1.wav', 'ref_audio_text': '我叫林亲堂1932年出生在美丽的邵阳', 'sample_rate': 24000, 'process_num': 2}, 'LLM_Bailian': {'enabled': True, 'module': 'llm/openai_compatible/llm_handler_dify_compatible', 'model_name': 'glm-4-flash-250414', 'enable_video_input': False, 'system_prompt': '请你扮演一个 AI 助手，用简短的两三句对话来回答用户的问题，并在对话内容中加入合适的标点符号，不需要讨论标点符号相关的内容', 'api_url': 'http://120.224.27.114:28080/v1', 'api_key': 'app-EvwPiCCHWM9K5c4xTWhvSMDP', 'dify_chat_messages': 'http://120.224.27.114:28080/v1/chat-messages', 'dify_code': 'app-EvwPiCCHWM9K5c4xTWhvSMDP', 'dify_upload': 'http://120.224.27.114:28080/v1/files/upload'}, 'LAM_Driver': {'module': 'avatar/lam/avatar_handler_lam_audio2expression'}} outputs={}
2025-06-28 09:51:19.152 | INFO     | service.service_utils.logger_utils:config_loggers:8 - Set log level to INFO
2025-06-28 09:51:19.352 | INFO     | chat_engine.core.handler_manager:initialize:47 - Use handler search path: ['/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers']
2025-06-28 09:51:19.352 | INFO     | chat_engine.core.handler_manager:initialize:71 - Try to load client.h5_rendering_client.client_handler_lam
2025-06-28 09:51:19.606 | INFO     | chat_engine.core.handler_manager:register_handler:128 - Registered handler LamClient(<class 'client.h5_rendering_client.client_handler_lam.ClientHandlerLam'>) with config: enabled=True module='client/h5_rendering_client/client_handler_lam' connection_ttl=900 concurrent_limit=5 turn_config=None asset_path='lam_samples/060201.zip'
2025-06-28 09:51:19.606 | INFO     | chat_engine.core.handler_manager:initialize:71 - Try to load vad.silerovad.vad_handler_silero
2025-06-28 09:51:19.610 | INFO     | chat_engine.core.handler_manager:register_handler:128 - Registered handler SileroVad(<class 'vad.silerovad.vad_handler_silero.HandlerAudioVAD'>) with config: enabled=True module='vad/silerovad/vad_handler_silero' speaking_threshold=0.5 start_delay=2048 end_delay=5000 buffer_look_back=5000 speech_padding=512
2025-06-28 09:51:19.610 | INFO     | chat_engine.core.handler_manager:initialize:71 - Try to load asr.sensevoice.asr_handler_sensevoice
2025-06-28 09:51:25.090 | INFO     | chat_engine.core.handler_manager:register_handler:128 - Registered handler SenseVoice(<class 'asr.sensevoice.asr_handler_sensevoice.HandlerASR'>) with config: enabled=True module='asr/sensevoice/asr_handler_sensevoice' model_name='iic/SenseVoiceSmall'
2025-06-28 09:51:25.090 | INFO     | chat_engine.core.handler_manager:initialize:71 - Try to load tts.cosyvoice.tts_handler_cosyvoice
2025-06-28 09:51:25.193 | INFO     | chat_engine.core.handler_manager:register_handler:128 - Registered handler CosyVoice(<class 'tts.cosyvoice.tts_handler_cosyvoice.HandlerTTS'>) with config: enabled=True module='tts/cosyvoice/tts_handler_cosyvoice' model_name='iic/CosyVoice2-0.5B' api_key=None api_url='http://127.0.0.1:40000/inference_zero_shot' ref_audio_path='/mnt/data/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/asset/my_voice_1.wav' ref_audio_text='我叫林亲堂1932年出生在美丽的邵阳' spk_id=None sample_rate=24000 process_num=2
2025-06-28 09:51:25.194 | INFO     | chat_engine.core.handler_manager:initialize:71 - Try to load llm.openai_compatible.llm_handler_dify_compatible
2025-06-28 09:51:25.927 | INFO     | chat_engine.core.handler_manager:register_handler:128 - Registered handler LLM_Bailian(<class 'llm.openai_compatible.llm_handler_dify_compatible.HandlerLLM'>) with config: enabled=True module='llm/openai_compatible/llm_handler_dify_compatible' model_name='glm-4-flash-250414' system_prompt='请你扮演一个 AI 助手，用简短的两三句对话来回答用户的问题，并在对话内容中加入合适的标点符号，不需要讨论标点符号相关的内容' api_key='app-EvwPiCCHWM9K5c4xTWhvSMDP' api_url='http://120.224.27.114:28080/v1' enable_video_input=False dify_chat_messages='http://120.224.27.114:28080/v1/chat-messages' dify_code='app-EvwPiCCHWM9K5c4xTWhvSMDP' dify_upload='http://120.224.27.114:28080/v1/files/upload'
2025-06-28 09:51:25.927 | INFO     | chat_engine.core.handler_manager:initialize:71 - Try to load avatar.lam.avatar_handler_lam_audio2expression
2025-06-28 09:51:25.930 | INFO     | chat_engine.core.handler_manager:register_handler:128 - Registered handler LAM_Driver(<class 'avatar.lam.avatar_handler_lam_audio2expression.HandlerAvatarLAM'>) with config: enabled=True module='avatar/lam/avatar_handler_lam_audio2expression' model_name='LAM_audio2exp' feature_extractor_model_name='wav2vec2-base-960h' audio_sample_rate=24000
2025-06-28 09:51:25.930 | INFO     | chat_engine.core.handler_manager:load_handlers:142 - Handler LamClient loaded in 0 milliseconds
2025-06-28 09:51:26.054 | INFO     | chat_engine.core.handler_manager:load_handlers:142 - Handler SileroVad loaded in 124 milliseconds
funasr version: 1.2.6.
Downloading Model from https://www.modelscope.cn to directory: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/SenseVoiceSmall
2025-06-28 09:51:31.940 | INFO     | chat_engine.core.handler_manager:load_handlers:142 - Handler SenseVoice loaded in 5886 milliseconds
2025-06-28 09:51:33,316 - modelscope - INFO - Target directory already exists, skipping creation.
Downloading Model from https://www.modelscope.cn to directory: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/CosyVoice2-0.5B
2025-06-28 09:51:37.524 | INFO     | handlers.tts.cosyvoice.cosyvoice_processor_new:run:53 - start tts processor
2025-06-28 09:51:37.778 | INFO     | handlers.tts.cosyvoice.cosyvoice_processor_new:run:53 - start tts processor
2025-06-28 09:51:39,320 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:39,500 DEBUG https://www.modelscope.cn:443 "GET /api/v1/repos/internalAccelerationInfo HTTP/1.1" 200 188
2025-06-28 09:51:39,502 DEBUG Starting new HTTP connection (1): 100.100.100.200:80
2025-06-28 09:51:39,611 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:39,704 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:39,807 DEBUG https://www.modelscope.cn:443 "GET /api/v1/repos/internalAccelerationInfo HTTP/1.1" 200 188
2025-06-28 09:51:39,810 DEBUG Starting new HTTP connection (1): 100.100.100.200:80
2025-06-28 09:51:39,932 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B HTTP/1.1" 200 None
2025-06-28 09:51:40,012 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:40,184 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/revisions HTTP/1.1" 200 362
2025-06-28 09:51:40,281 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B HTTP/1.1" 200 None
2025-06-28 09:51:40,443 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/revisions HTTP/1.1" 200 362
2025-06-28 09:51:40,479 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/repo/files?Revision=master&Recursive=True HTTP/1.1" 200 None
2025-06-28 09:51:40,481 - modelscope - INFO - Target directory already exists, skipping creation.
2025-06-28 09:51:40,487 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:40,685 DEBUG https://www.modelscope.cn:443 "GET /api/v1/repos/internalAccelerationInfo HTTP/1.1" 200 188
2025-06-28 09:51:40,688 DEBUG Starting new HTTP connection (1): 100.100.100.200:80
2025-06-28 09:51:40,730 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/repo/files?Revision=master&Recursive=True HTTP/1.1" 200 None
2025-06-28 09:51:40,731 - modelscope - INFO - Target directory already exists, skipping creation.
2025-06-28 09:51:40,733 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:40,890 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:40,945 DEBUG https://www.modelscope.cn:443 "GET /api/v1/repos/internalAccelerationInfo HTTP/1.1" 200 188
2025-06-28 09:51:40,947 DEBUG Starting new HTTP connection (1): 100.100.100.200:80
2025-06-28 09:51:41,132 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B HTTP/1.1" 200 None
2025-06-28 09:51:41,150 DEBUG Starting new HTTPS connection (1): www.modelscope.cn:443
2025-06-28 09:51:41,281 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/revisions HTTP/1.1" 200 362
2025-06-28 09:51:41,360 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B HTTP/1.1" 200 None
2025-06-28 09:51:41,510 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/revisions HTTP/1.1" 200 362
2025-06-28 09:51:41,604 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/repo/files?Revision=master&Recursive=True HTTP/1.1" 200 None
2025-06-28 09:51:41,606 - modelscope - INFO - Target directory already exists, skipping creation.
2025-06-28 09:51:41,818 DEBUG https://www.modelscope.cn:443 "GET /api/v1/models/iic/CosyVoice2-0.5B/repo/files?Revision=master&Recursive=True HTTP/1.1" 200 None
2025-06-28 09:51:41,820 - modelscope - INFO - Target directory already exists, skipping creation.
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/lightning/fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/lightning/fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
  deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.
  deprecate("LoRACompatibleLinear", "1.0.0", deprecation_message)
2025-06-28 09:51:45,952 INFO input frame rate=25
2025-06-28 09:51:46,088 INFO input frame rate=25
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'
  warnings.warn(
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'
  warnings.warn(
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/frontend.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.spk2info = torch.load(spk2info, map_location=self.device)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/frontend.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.spk2info = torch.load(spk2info, map_location=self.device)
2025-06-28 09:51:50,110 WETEXT INFO building fst for zh_normalizer ...
2025-06-28 09:51:50,110 INFO building fst for zh_normalizer ...
2025-06-28 09:51:50,288 WETEXT INFO building fst for zh_normalizer ...
2025-06-28 09:51:50,288 INFO building fst for zh_normalizer ...
2025-06-28 09:52:28,200 WETEXT INFO done
2025-06-28 09:52:28,200 INFO done
2025-06-28 09:52:28,200 WETEXT INFO fst path: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_tagger.fst
2025-06-28 09:52:28,200 INFO fst path: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_tagger.fst
2025-06-28 09:52:28,201 WETEXT INFO           /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_verbalizer.fst
2025-06-28 09:52:28,201 INFO           /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_verbalizer.fst
2025-06-28 09:52:28,210 WETEXT INFO found existing fst: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_tagger.fst
2025-06-28 09:52:28,210 INFO found existing fst: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_tagger.fst
2025-06-28 09:52:28,210 WETEXT INFO                     /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_verbalizer.fst
2025-06-28 09:52:28,210 INFO                     /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_verbalizer.fst
2025-06-28 09:52:28,210 WETEXT INFO skip building fst for en_normalizer ...
2025-06-28 09:52:28,210 INFO skip building fst for en_normalizer ...
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.llm.load_state_dict(torch.load(llm_model, map_location=self.device), strict=True)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.flow.load_state_dict(torch.load(flow_model, map_location=self.device), strict=True)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  hift_state_dict = {k.replace('generator.', ''): v for k, v in torch.load(hift_model, map_location=self.device).items()}
2025-06-28 09:52:35,151 WETEXT INFO done
2025-06-28 09:52:35,151 INFO done
2025-06-28 09:52:35,151 WETEXT INFO fst path: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_tagger.fst
2025-06-28 09:52:35,151 INFO fst path: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_tagger.fst
2025-06-28 09:52:35,151 WETEXT INFO           /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_verbalizer.fst
2025-06-28 09:52:35,151 INFO           /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/zh_tn_verbalizer.fst
2025-06-28 09:52:35,157 WETEXT INFO found existing fst: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_tagger.fst
2025-06-28 09:52:35,157 INFO found existing fst: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_tagger.fst
2025-06-28 09:52:35,158 WETEXT INFO                     /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_verbalizer.fst
2025-06-28 09:52:35,158 INFO                     /mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/tn/en_tn_verbalizer.fst
2025-06-28 09:52:35,158 WETEXT INFO skip building fst for en_normalizer ...
2025-06-28 09:52:35,158 INFO skip building fst for en_normalizer ...
failed to import ttsfrd, use WeTextProcessing instead
Downloading Model from https://www.modelscope.cn to directory: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/CosyVoice2-0.5B
Downloading Model from https://www.modelscope.cn to directory: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/CosyVoice2-0.5B
  0%|          | 0/1 [00:00<?, ?it/s]2025-06-28 09:52:36,059 INFO synthesis text 欢迎来到中国两千零二十五。
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with self.llm_context, torch.cuda.amp.autocast(self.fp16 is True and hasattr(self.llm, 'vllm') is False):
We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.llm.load_state_dict(torch.load(llm_model, map_location=self.device), strict=True)
Exception in thread Thread-3 (llm_job):
Traceback (most recent call last):
  File "/root/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
    self.run()
  File "/root/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py", line 115, in llm_job
    for i in self.llm.inference(text=text.to(self.device),
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 36, in generator_context
    response = gen.send(None)
               ^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/llm/llm.py", line 415, in inference
    for token in self.inference_wrapper(lm_input, sampling, min_len, max_len, uuid):
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 36, in generator_context
    response = gen.send(None)
               ^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/llm/llm.py", line 453, in inference_wrapper
    y_pred, cache = self.llm.forward_one_step(lm_input,
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/llm/llm.py", line 249, in forward_one_step
    outs = self.model(
           ^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 1104, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 915, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 669, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 223, in forward
    return self.down_proj(self.act_fn(self.gate_proj(hidden_state)) * self.up_proj(hidden_state))
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 21.66 GiB of which 20.81 MiB is free. Process 3868718 has 3.65 GiB memory in use. Process 184800 has 4.36 GiB memory in use. Process 2046859 has 1.66 GiB memory in use. Process 2048004 has 3.22 GiB memory in use. Process 2048003 has 3.22 GiB memory in use. Process 3639 has 1.09 GiB memory in use. Process 64792 has 1.09 GiB memory in use. Including non-PyTorch memory, this process has 3.18 GiB memory in use. Process 65856 has 176.00 MiB memory in use. Of the allocated memory 2.81 GiB is allocated by PyTorch, and 170.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Process TTSCosyVoiceProcessor-3:
Traceback (most recent call last):
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/cosyvoice_processor_new.py", line 61, in run
    self.model = CosyVoice(model_dir=self.model_name)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/cosyvoice.py", line 37, in __init__
    raise ValueError('{} not found!'.format(hyper_yaml_path))
ValueError: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/CosyVoice2-0___5B/cosyvoice.yaml not found!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/cosyvoice_processor_new.py", line 64, in run
    self.model = CosyVoice2(model_dir=self.model_name)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/cosyvoice.py", line 167, in __init__
    self.model.load('{}/llm.pt'.format(model_dir),
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/CosyVoice/cosyvoice/cli/model.py", line 68, in load
    self.llm.load_state_dict(torch.load(llm_model, map_location=self.device), strict=True)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 1360, in load
    return _load(
           ^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 1848, in _load
    result = unpickler.load()
             ^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 1812, in persistent_load
    typed_storage = load_tensor(
                    ^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 1784, in load_tensor
    wrap_storage=restore_location(storage, location),
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 1690, in restore_location
    return default_restore_location(storage, str(map_location))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 601, in default_restore_location
    result = fn(storage, location)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/serialization.py", line 540, in _deserialize
    return obj.to(device=device)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/storage.py", line 279, in to
    return _to(self, device, non_blocking)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/.venv/lib/python3.11/site-packages/torch/_utils.py", line 88, in _to
    untyped_storage = torch.UntypedStorage(self.size(), device=device)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 520.00 MiB. GPU 0 has a total capacity of 21.66 GiB of which 20.81 MiB is free. Process 3868718 has 3.65 GiB memory in use. Process 184800 has 4.36 GiB memory in use. Process 2046859 has 1.66 GiB memory in use. Process 2048004 has 3.22 GiB memory in use. Process 2048003 has 3.22 GiB memory in use. Process 3639 has 1.09 GiB memory in use. Process 64792 has 1.09 GiB memory in use. Process 65855 has 3.18 GiB memory in use. Including non-PyTorch memory, this process has 176.00 MiB memory in use. Of the allocated memory 1.26 MiB is allocated by PyTorch, and 755.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/mnt/data/open-avatar-chat/opt/OpenAvatarChat/src/handlers/tts/cosyvoice/cosyvoice_processor_new.py", line 66, in run
    raise TypeError('no valid model_type!')
TypeError: no valid model_type!
failed to import ttsfrd, use WeTextProcessing instead
Downloading Model from https://www.modelscope.cn to directory: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/CosyVoice2-0.5B
Downloading Model from https://www.modelscope.cn to directory: /mnt/data/open-avatar-chat/opt/OpenAvatarChat/models/iic/CosyVoice2-0.5B
